{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 2.3 Starter Code\n",
    "\n",
    "See pset 1 for dependency installation instructions and see the problem set for deliverables.\n",
    "\n",
    "As in the previous problem set, you may find this notebook useful as a reference for logical data structures: https://github.com/aimacode/aima-python/blob/master/logic.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run this once ever 12 hours)\n",
    "!git clone https://github.com/MIT-6-882/HW utils\n",
    "!pip install tabulate\n",
    "!pip install python-sat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.logic_utils import Expr, expr, FolKB, implies\n",
    "from collections import defaultdict\n",
    "import abc\n",
    "import itertools\n",
    "import heapq as hq\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First-order Horn Clause Set Learning\n",
    "Learn a set of first-order Horn clauses using best-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOLHornClauseSetLearner(FolKB):\n",
    "    \"\"\"Learn a set of first-order Horn clauses, and answer queries\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_rule_size : int\n",
    "        The maximum number of predicates in the body of any\n",
    "        learned rule. Used to bound learning.\n",
    "    max_rules : int\n",
    "        The maximum number of rules that can be learned.\n",
    "    max_search_iters : int\n",
    "        The maximum number of nodes to expand during the search\n",
    "        for a single new rule.\n",
    "    terminate_early : bool\n",
    "        Whether to stop learning as soon as a set of rules is\n",
    "        found that perfectly cover the training examples.\n",
    "    score_mode : str\n",
    "        Name of the scoring heuristic used. Currently \"coverage\"\n",
    "        is allowed.\n",
    "    size_penalty_weight : float\n",
    "        A weight used to regularize the size of rules, preferring\n",
    "        smaller ones.\n",
    "    \"\"\"\n",
    "    def __init__(self, max_rule_size=3, max_rules=10, max_search_iters=1000,\n",
    "                 terminate_early=True, score_mode=\"coverage\", \n",
    "                 size_penalty_weight=0.1, *args, **kwargs):\n",
    "        # Note that the learned rules are stored in self.clauses, which\n",
    "        # is initialized in the parent class\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.max_rule_size = max_rule_size\n",
    "        self.max_rules = max_rules\n",
    "        self.max_search_iters = max_search_iters\n",
    "        self.terminate_early = terminate_early\n",
    "        self.score_mode = score_mode\n",
    "        self.size_penalty_weight = size_penalty_weight\n",
    "\n",
    "    ## Inference\n",
    "\n",
    "    def check(self, query, assumptions=None):\n",
    "        \"\"\"Check whether a query is entailed by the learned rules and\n",
    "        optionally, additional assumptions.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        query : expr\n",
    "            A logical sentence to check\n",
    "        assumptions : [ expr ]\n",
    "            Logical sentences to add to the antecendent\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        entailed : bool\n",
    "            True if query is entailed by the learned rules and\n",
    "            assumptions.\n",
    "        \"\"\"\n",
    "        # Add assumptions tentatively, then remove\n",
    "        if assumptions is not None:\n",
    "            for s in assumptions:\n",
    "                self.tell(s)\n",
    "        result = self.ask(query)\n",
    "        # Remove assumptions\n",
    "        if assumptions is not None:\n",
    "            for s in assumptions:\n",
    "                self.retract(s)\n",
    "        return result\n",
    "\n",
    "    ## Main learning function\n",
    "\n",
    "    def train(self, training_data):\n",
    "        \"\"\"Learn a set of first-order Horn clauses from training data\n",
    "\n",
    "        Training proceeds by greedily finding one rule at a time to \n",
    "        add to the overall rule set. The way that each rule is selected\n",
    "        varies depending on the subclass, but always involves a search\n",
    "        over rules with a heuristic scorer.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            Each training datum is a triple of\n",
    "            (input, positive outs, negative outs). For example:\n",
    "\n",
    "            obs = {\n",
    "                at(\"Main\"),\n",
    "                isYellow(\"Main\"),\n",
    "                isGreen(\"Park\"),\n",
    "                isYellow(\"Central\"),\n",
    "            }\n",
    "            good_actions = { wait() }\n",
    "            bad_actions = { go() }\n",
    "\n",
    "            One datum would then be (obs, good_actions, bad_actions).\n",
    "        \"\"\"\n",
    "        # Initialize rules\n",
    "        self.clauses = []\n",
    "\n",
    "        # Extract the predicates that are allowed in the head\n",
    "        # and body of the rule\n",
    "        input_predicates, output_predicates = self._extract_predicates(\n",
    "            training_data)\n",
    "\n",
    "        # Keep track of the overall score (lower is better)\n",
    "        score = float(\"inf\")\n",
    "\n",
    "        # Repeat until all examples are covered or until max_rules\n",
    "        for it in range(self.max_rules):\n",
    "\n",
    "            # Find a new rule set\n",
    "            new_rule, new_score = self._find_new_rule(training_data, \n",
    "                input_predicates, output_predicates)\n",
    "\n",
    "            # Terminate\n",
    "            if not new_rule or new_score >= score:\n",
    "                break\n",
    "\n",
    "            score = new_score\n",
    "\n",
    "            # Add new rule to clauses\n",
    "            new_clause = self._rule_to_clause(new_rule)\n",
    "            assert new_clause not in self.clauses, \\\n",
    "                \"Tried to add a rule that is already in the rule set\"\n",
    "            self.tell(new_clause)\n",
    "\n",
    "            # Check whether we're done\n",
    "            if self._all_examples_covered(training_data):\n",
    "                print(f\"Training finished after {it+1} iterations.\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"Training did not converge, giving up.\")\n",
    "\n",
    "        print(\"Final rules:\\n \", \"\\n  \".join(map(str, self.clauses)))\n",
    "\n",
    "    ## Learning a single rule\n",
    "\n",
    "    def _find_new_rule(self, training_data, input_predicates, output_predicates):\n",
    "        \"\"\"Propose a rule to add to the rule set.\n",
    "\n",
    "        Works by performing a search, where the state of the search is a single\n",
    "        candidate rule (Horn clause). The initialization of the search and the\n",
    "        successor function are what distinguish subclasses.\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            See self.train docstring\n",
    "        input_predicates : { (str, int) }\n",
    "            A set of predicates, where each predicate is a\n",
    "            (name, arity) [recall \"arity\" means # of args].\n",
    "            These are the predicates that can be involved\n",
    "            in the body of the rules.\n",
    "        output_predicates : { (str, int) }\n",
    "            These are the predicates that can be involved\n",
    "            in the head of the rules.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        new_rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        score : float\n",
    "            Used to determine whether to terminate the outer search.\n",
    "            Lower is better.\n",
    "        \"\"\"\n",
    "        # Initialize search\n",
    "        tiebreak = itertools.count()\n",
    "        queue = []\n",
    "        best_score = float(\"inf\")\n",
    "        best_rule = None\n",
    "        visited = set()\n",
    "\n",
    "        for rule in self._get_initial_rules(training_data, output_predicates):\n",
    "            hq.heappush(queue, (-float(\"inf\"), next(tiebreak), rule))\n",
    "\n",
    "        # Run the search\n",
    "        for it in range(self.max_search_iters):\n",
    "            print(f\"Iteration {it}\", end='\\r')\n",
    "            # Check if we've exhausted the queue\n",
    "            if len(queue) == 0:\n",
    "                break\n",
    "            # Get a rule to extend\n",
    "            _, _, rule = hq.heappop(queue)\n",
    "            # Consider different extensions\n",
    "            for child in self._get_successors(rule, input_predicates):\n",
    "                # No need to reconsider children\n",
    "                if child in visited:\n",
    "                    continue\n",
    "                # Don't consider children that are too large\n",
    "                if len(child[0]) > self.max_rule_size:\n",
    "                    continue\n",
    "                # Score the child\n",
    "                child_score = self._score_rule(child, training_data)\n",
    "                # Update best score\n",
    "                if child_score < best_score and \\\n",
    "                    not self._rule_is_malformed(child):\n",
    "                    best_score = child_score\n",
    "                    best_rule = child\n",
    "                    print(\"Updating best rule:\", best_rule)\n",
    "                    # Perfect fit, terminate early\n",
    "                    if self.terminate_early and child_score == float(\"-inf\"):\n",
    "                        print(\"\\nFound perfect rule:\")\n",
    "                        print(best_rule)\n",
    "                        return best_rule, best_score\n",
    "                # Add to the queue\n",
    "                hq.heappush(queue, (child_score, next(tiebreak), child))\n",
    "                visited.add(child)\n",
    "\n",
    "        print(\"\\nTerminated without a perfect rule\")\n",
    "        if best_score < 0: # negative means some improvemment\n",
    "            print(f\"Best rule found (score {best_score}):\")\n",
    "            print(best_rule)\n",
    "            return best_rule, best_score\n",
    "        print(\"Could not find any rule that improves overall\")\n",
    "        return False\n",
    "\n",
    "    def _score_rule(self, rule, training_data):\n",
    "        \"\"\"Give a heuristic score to a candidate rule that we are\n",
    "        considering adding to our overall rule set.\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            See self.train docstring\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        score : float\n",
    "            Lower is better\n",
    "        \"\"\"\n",
    "        if self.score_mode == \"coverage\":\n",
    "            score = self._score_rule_with_coverage(rule, training_data)\n",
    "        else:\n",
    "            raise Exception(f\"Unrecognized score mode {mode}\")\n",
    "\n",
    "        # Add size penalty\n",
    "        rule_size = len(rule[0])\n",
    "        score += self.size_penalty_weight*rule_size\n",
    "\n",
    "        return score\n",
    "\n",
    "    def _score_rule_with_coverage(self, rule, training_data):\n",
    "        \"\"\"Count the number of negative and positive examples\n",
    "        covered by the rule in the training data, and give a score\n",
    "        of simply # negatives - # positives.\n",
    "        \"\"\"\n",
    "        # If the rule is malformed, it explains nothing\n",
    "        if self._rule_is_malformed(rule):\n",
    "            return 0\n",
    "\n",
    "        # We will count the number of correct overall to see\n",
    "        # if we should terminate early\n",
    "        all_correct = True\n",
    "        num_true_positives = 0\n",
    "        num_false_positives = 0\n",
    "        # Convert from manipulable representation to AIMA expr\n",
    "        # so that we can call self.check\n",
    "        new_clause = self._rule_to_clause(rule)\n",
    "        for x, pos_y, neg_y in training_data:\n",
    "            assumptions = [new_clause] + list(x)\n",
    "            for y in pos_y:\n",
    "                # Does the new clause and the training data\n",
    "                # (together with the old clauses) imply the\n",
    "                # positive example?\n",
    "                if self.check(y, assumptions=assumptions):\n",
    "                    num_true_positives += 1\n",
    "                else:\n",
    "                    all_correct = False\n",
    "            for y in neg_y:\n",
    "                # Does the new clause and the training data\n",
    "                # (together with the old clauses) imply the\n",
    "                # negative example?\n",
    "                if self.check(y, assumptions=assumptions):\n",
    "                    num_false_positives += 1\n",
    "                    all_correct = False\n",
    "        score = num_false_positives - num_true_positives\n",
    "        # Check if perfect\n",
    "        if self.terminate_early and all_correct:\n",
    "            return -float(\"inf\")\n",
    "        return score\n",
    "\n",
    "    def _get_possible_groundings(self, predicate, available_variables):\n",
    "        \"\"\"Get all possible groundings of the predicate over variables.\n",
    "        Allow groundings over the available variables, or over fresh vars.\n",
    "\n",
    "        Helper for learning new rules.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicate : (str, int)\n",
    "            See self._extract_predicates\n",
    "        available_variables : { int }\n",
    "            See self._expr_to_variables\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        ground_predicate : expr\n",
    "            See self._ground_predicate\n",
    "        \"\"\"\n",
    "        _, arity = predicate\n",
    "        max_var = 0 if len(available_variables) == 0 else max(available_variables)\n",
    "        available_variables = sorted(available_variables)\n",
    "\n",
    "        for num_new_variables in range(arity+1):\n",
    "            # Allow groundings over \"fresh\" variables\n",
    "            new_vars = list(range(max_var+1, max_var+1+num_new_variables))\n",
    "            for choice in itertools.product(available_variables+new_vars, \n",
    "                                            repeat=arity):\n",
    "                # Skip if new vars are not in order\n",
    "                new_vars_in_choice = [v for v in choice if v in new_vars]\n",
    "                if new_vars_in_choice != sorted(new_vars_in_choice):\n",
    "                    continue\n",
    "                # Skip if min new var is not min\n",
    "                if len(new_vars_in_choice) and \\\n",
    "                    (min(new_vars_in_choice) != min(new_vars)):\n",
    "                    continue\n",
    "                yield self._ground_predicate(predicate, choice)\n",
    "\n",
    "    def _all_examples_covered(self, training_data):\n",
    "        \"\"\"Check whether all training data are covered (we'll stop if so)\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            See self.train docstring\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        covered : bool\n",
    "        \"\"\"\n",
    "        for x, pos_y, neg_y in training_data:\n",
    "            for y in pos_y:\n",
    "                # Does x imply y (with the rules)?\n",
    "                if not self.check(y, assumptions=list(x)):\n",
    "                    return False\n",
    "            for y in neg_y:\n",
    "                # Does x imply y (with the rules)?\n",
    "                if self.check(y, assumptions=list(x)):\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    ## Helpers for converting between AIMA and more manipulable representations\n",
    "\n",
    "    def _extract_predicates(self, training_data):\n",
    "        \"\"\"Identify the predicates in the inputs and outputs of the data\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            See self.train docstring\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        input_predicates : { (str, int) }\n",
    "            A set of predicates, where each predicate is a\n",
    "            (name, arity) [recall \"arity\" means # of args].\n",
    "            These are the predicates that can be involved\n",
    "            in the body of the rules.\n",
    "        output_predicates : { (str, int) }\n",
    "            These are the predicates that can be involved\n",
    "            in the head of the rules.\n",
    "        \"\"\"\n",
    "        input_predicates = set()\n",
    "        output_predicates = set()\n",
    "\n",
    "        for x, pos_y, neg_y in training_data:\n",
    "            # Input predicates\n",
    "            for x_i in x:\n",
    "                predicate = self._expr_to_predicate(x_i)\n",
    "                input_predicates.add(predicate)\n",
    "            # Output predicates\n",
    "            for y_i in pos_y | neg_y:\n",
    "                predicate = self._expr_to_predicate(y_i)\n",
    "                output_predicates.add(predicate)\n",
    "\n",
    "        return input_predicates, output_predicates\n",
    "\n",
    "    def _expr_to_predicate(self, expr):\n",
    "        \"\"\"Extract a predicate from a AIMA logical expr.\n",
    "\n",
    "        For example, if the expr is Green(Main), this\n",
    "        will return (\"Green\", 1), where the first element\n",
    "        is the name of the predicate and the second element\n",
    "        is the arity, i.e., the number of arguments to the\n",
    "        predicate.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expr : expr\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        predicate : (str, int)\n",
    "        \"\"\"\n",
    "        arity = len(expr.args)\n",
    "        name = expr.op\n",
    "        return (name, arity)\n",
    "\n",
    "    def _expr_to_variables(self, expr):\n",
    "        \"\"\"Extract all of the variables from an AIMA logical expr\n",
    "        representing a predicate.\n",
    "\n",
    "        Note that variables are represented as integers during\n",
    "        learning.\n",
    "\n",
    "        For example, if the expr is Green(x5), this\n",
    "        will return {5}.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        expr : expr\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        variables : { int }\n",
    "        \"\"\"\n",
    "        variables = { int(str(a)[1:]) for a in expr.args }\n",
    "        return variables\n",
    "\n",
    "    def _ground_predicate(self, predicate, variables):\n",
    "        \"\"\"Create an AIMA logical expr for a ground predicate\n",
    "        given the predicate and variables.\n",
    "\n",
    "        For example, if predicate is (\"green\", 1) and the\n",
    "        variables are [5], then this will return the expr\n",
    "        Green(x5).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        predicate : (str, int)\n",
    "            See _expr_to_predicate.\n",
    "        variables : [ int ]\n",
    "            See _expr_to_variables.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ground_predicate : expr\n",
    "        \"\"\"\n",
    "        name, arity = predicate\n",
    "        assert len(variables) == arity\n",
    "        args = [f\"x{i}\" for i in variables]\n",
    "        return expr(str(name) + \"(\" + \",\".join(args) + \")\")\n",
    "\n",
    "    def _rule_to_clause(self, rule):\n",
    "        \"\"\"Convert from manipulable rule into AIMA expr.\n",
    "\n",
    "        For example, if rule is ({Green(Main), Yellow(Park)}, Go()),\n",
    "        then this will return Green(Main) & Yellow(Park) ==> Go().\n",
    "        \"\"\"\n",
    "        body, head = rule\n",
    "        query = implies(Expr(\"&\", *body), head)\n",
    "        return query\n",
    "\n",
    "    ## Other helper methods\n",
    "\n",
    "    def _rule_is_malformed(self, rule):\n",
    "        \"\"\"A rule is malformed if not all head variables appear in the body\n",
    "        \"\"\"\n",
    "        body_vars = {v for a in rule[0] for v in self._expr_to_variables(a)}\n",
    "        head_vars = self._expr_to_variables(rule[1])\n",
    "        return not head_vars.issubset(body_vars)\n",
    "\n",
    "    def _subst(self, subs, x):\n",
    "        \"\"\"Substitute into an expression x\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        subs : { expr : expr }\n",
    "            Substitute keys to values.\n",
    "        x : expr\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x' : expr\n",
    "        \"\"\"\n",
    "        if isinstance(x, list):\n",
    "            return [self._subst(subs, i) for i in x]\n",
    "        if isinstance(x, frozenset):\n",
    "            return frozenset({self._subst(subs, i) for i in x})\n",
    "        if isinstance(x, set):\n",
    "            return {self._subst(subs, i) for i in x}\n",
    "        if x in subs:\n",
    "            return subs[x]\n",
    "        if hasattr(x, \"args\"):\n",
    "            new_args = [self._subst(subs, a) for a in x.args]\n",
    "            return Expr(x.op, *new_args)\n",
    "        raise Exception(\"Substitution failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top-Down Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopDownLearner(FOLHornClauseSetLearner):\n",
    "    \"\"\"A top-down FOL horn clause set learner.\n",
    "\n",
    "    It is top-down because it searches over individual rules by\n",
    "    starting with empty rules and gradually adds more and more\n",
    "    clauses.\n",
    "    \"\"\"\n",
    "    def _get_initial_rules(self, _, output_predicates):\n",
    "        \"\"\"Get rules to initialize the search for a new rule\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        output_predicates : { (str, int) }\n",
    "            These are the predicates that can be involved\n",
    "            in the head of the rules.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        new_rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        \"\"\"\n",
    "        # Start with the output predicates alone\n",
    "        for output_predicate in output_predicates:\n",
    "            _, predicate_arity = output_predicate\n",
    "            consequent = self._ground_predicate(output_predicate,\n",
    "                range(predicate_arity))\n",
    "            yield (frozenset(), consequent)\n",
    "\n",
    "    def _get_successors(self, rule, input_predicates):\n",
    "        \"\"\"Consider adding new single predicates to the rule body\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        input_predicates : { (str, int) }\n",
    "            A set of predicates, where each predicate is a\n",
    "            (name, arity) [recall \"arity\" means # of args].\n",
    "            These are the predicates that can be involved\n",
    "            in the body of the rules.\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        new_rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        \"\"\"\n",
    "        body, head = rule\n",
    "        # Get the variables that are already in the rule\n",
    "        available_variables = self._expr_to_variables(head)\n",
    "        for atom in body:\n",
    "            available_variables.update(self._expr_to_variables(atom))\n",
    "        # Consider predicates to add\n",
    "        for predicate in input_predicates:\n",
    "            # Consider groundings of the predicate\n",
    "            for candidate in self._get_possible_groundings(predicate, \n",
    "                available_variables):\n",
    "                # Don't add if already in\n",
    "                if candidate in body:\n",
    "                    continue\n",
    "                yield (frozenset(list(body) + [candidate]), head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottom-Up Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottomUpLearner(FOLHornClauseSetLearner):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # We're going bottom up, so we don't need to specify a max rule\n",
    "        # size. We also don't want to terminate early because we may\n",
    "        # perfectly fit the data but want to still prune the rules.\n",
    "        super().__init__(max_rule_size=float(\"inf\"), terminate_early=False,\n",
    "            *args, **kwargs)\n",
    "\n",
    "    def _get_initial_rules(self, training_data, _):\n",
    "        \"\"\"Get rules to initialize the search for a new rule\n",
    "\n",
    "        For bottom-up learning, these rules are just the data, but\n",
    "        lifted, i.e., substituing the objects with variables.\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        training_data : [({expr}, {expr}, {expr})]\n",
    "            See self.train docstring\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        new_rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        \"\"\"\n",
    "        proposals = set()\n",
    "        # Propose one rule per positive training example\n",
    "        # by \"lifting\" the constants\n",
    "        for x, pos_y, _ in training_data:\n",
    "            for y in pos_y:\n",
    "                constants = set(y.args)\n",
    "                for x_i in x:\n",
    "                    constants.update(x_i.args)\n",
    "                constant_to_var = { c : expr(f\"x{i+1}\") for i, c in \\\n",
    "                                    enumerate(sorted(constants)) }\n",
    "                new_x = frozenset(self._subst(constant_to_var, x))\n",
    "                new_y = self._subst(constant_to_var, y)\n",
    "                proposals.add((new_x, new_y))\n",
    "        return sorted(proposals)\n",
    "\n",
    "    def _get_successors(self, rule, _):\n",
    "        \"\"\"Consider removing single predicates from the rule body\n",
    "\n",
    "        Rules are represented with as a tuple (body, head) where body is\n",
    "        a frozenset containing the expr's that are conjoined in the body,\n",
    "        and head is the single expr representing the consequent of the Horn clause.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "\n",
    "        Yields\n",
    "        ------\n",
    "        new_rule : (frozenset(expr), expr)\n",
    "            See above\n",
    "        \"\"\"\n",
    "        # Propose children by deleting predicates from the body\n",
    "        rule_size = len(rule[0])\n",
    "        head = rule[1]\n",
    "        for i in range(rule_size):\n",
    "            body = tuple([e for j, e in enumerate(rule[0]) if i != j])\n",
    "            new_rule = (body, head)\n",
    "            yield new_rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ilp_model(method):\n",
    "    \"\"\"Create an ILP model by name\n",
    "    \"\"\"\n",
    "    if method == \"top_down\":\n",
    "        return TopDownLearner()\n",
    "    if method == \"bottom_up\":\n",
    "        return BottomUpLearner()\n",
    "    raise Exception(f\"Unknown ILP method {method}\")\n",
    "    \n",
    "def _test_ilp_helper(training_data, test_data, methods=(\"top_down\", \"bottom_up\")):\n",
    "    \"\"\"Helper for testing ILP methods\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    for method in methods:\n",
    "        print(f\"Testing method {method}\")\n",
    "        # Initialize\n",
    "        model = create_ilp_model(method)\n",
    "        # Train\n",
    "        model.train(training_data)\n",
    "        # Test\n",
    "        for obs, good_outputs, bad_outputs in test_data:\n",
    "            for y in good_outputs:\n",
    "                assert model.check(y, assumptions=list(obs)), \\\n",
    "                    f\"Model checking failed for positive example {obs, y}\"\n",
    "            for y in bad_outputs:\n",
    "                assert not model.check(y, assumptions=list(obs)), \\\n",
    "                    f\"Model checking failed for negative example {obs, y}\"\n",
    "\n",
    "    print(f\"Test passed in {time.time()-start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_traffic_light():\n",
    "    \"\"\"Learn a rule for what to do at a traffic light\n",
    "\n",
    "    (We're basically making self-driving cars!!!)\n",
    "\n",
    "    Target rules\n",
    "    ------------\n",
    "    at(x) & isGreen(x) => go()\n",
    "    at(x) & isYellow(x) => wait()\n",
    "    at(x) & isRed(x) => wait()\n",
    "    \"\"\"\n",
    "    def at(x):\n",
    "        return expr(f\"At({x})\")\n",
    "\n",
    "    def isGreen(x):\n",
    "        return expr(f\"IsGreen({x})\")\n",
    "\n",
    "    def isYellow(x):\n",
    "        return expr(f\"IsYellow({x})\")\n",
    "\n",
    "    def isRed(x):\n",
    "        return expr(f\"IsRed({x})\")\n",
    "\n",
    "    def go():\n",
    "        return expr(f\"Go()\")\n",
    "\n",
    "    def wait():\n",
    "        return expr(f\"Wait()\")\n",
    "\n",
    "    # Observations, positive actions, negative actions\n",
    "    training_data = []\n",
    "    obs = {\n",
    "        at(\"Main\"),\n",
    "        isGreen(\"Main\"),\n",
    "        isYellow(\"Park\"),\n",
    "        isRed(\"Central\"),\n",
    "    }\n",
    "    good_actions = { go() }\n",
    "    bad_actions = { wait() }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "    \n",
    "    obs = {\n",
    "        at(\"Main\"),\n",
    "        isYellow(\"Main\"),\n",
    "        isYellow(\"Park\"),\n",
    "        isRed(\"Central\"),\n",
    "    }\n",
    "    good_actions = { wait() }\n",
    "    bad_actions = { go() }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        at(\"Main\"),\n",
    "        isYellow(\"Main\"),\n",
    "        isGreen(\"Park\"),\n",
    "        isYellow(\"Central\"),\n",
    "    }\n",
    "    good_actions = { wait() }\n",
    "    bad_actions = { go() }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        at(\"Main\"),\n",
    "        isGreen(\"Main\"),\n",
    "        isGreen(\"Park\"),\n",
    "        isYellow(\"Central\"),\n",
    "    }\n",
    "    good_actions = { go() }\n",
    "    bad_actions = { wait() }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        at(\"Main\"),\n",
    "        isRed(\"Main\"),\n",
    "        isGreen(\"Park\"),\n",
    "        isYellow(\"Central\"),\n",
    "    }\n",
    "    good_actions = { wait() }\n",
    "    bad_actions = { go() }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    test_data = []\n",
    "\n",
    "    obs = {\n",
    "        at(\"Glen\"),\n",
    "        isGreen(\"Glen\"),\n",
    "    }\n",
    "    good_actions = { go() }\n",
    "    bad_actions = { wait() }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        at(\"Glen\"),\n",
    "        isYellow(\"Glen\"),\n",
    "    }\n",
    "    good_actions = { wait() }\n",
    "    bad_actions = { go() }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        at(\"Glen\"),\n",
    "        isRed(\"Glen\"),\n",
    "    }\n",
    "    good_actions = { wait() }\n",
    "    bad_actions = { go() }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    _test_ilp_helper(training_data, test_data)\n",
    "\n",
    "\n",
    "def test_search_and_rescue_policy_learning():\n",
    "    \"\"\"Learn a policy for search and rescue from positive and negative\n",
    "    examples of each action.\n",
    "\n",
    "    Target rules\n",
    "    ------------\n",
    "    personAt(x) & robotNotAtPerson() & handEmpty() => goTo(x)\n",
    "    personAt(x) & robotAt(x) & handEmpty() => pickUp()\n",
    "    hospitalAt(x) & robotNotAtHospital() & handFull() => goTo(x)\n",
    "    hospitalAt(x) & robotAt(x) & handFull() => putDown()\n",
    "    \"\"\"\n",
    "    def personAt(x):\n",
    "        return expr(f\"PersonAt({x})\")\n",
    "\n",
    "    def robotAt(x):\n",
    "        return expr(f\"RobotAt({x})\")\n",
    "\n",
    "    def robotNotAtPerson():\n",
    "        return expr(f\"RobotNotAtPerson()\")\n",
    "\n",
    "    def robotNotAtHospital():\n",
    "        return expr(f\"RobotNotAtHospital\")\n",
    "\n",
    "    def hospitalAt(x):\n",
    "        return expr(f\"HospitalAt({x})\")\n",
    "\n",
    "    def handEmpty():\n",
    "        return expr(f\"HandEmpty()\")\n",
    "\n",
    "    def handFull():\n",
    "        return expr(f\"HandFull()\")\n",
    "\n",
    "    def goTo(x):\n",
    "        return expr(f\"GoTo({x})\")\n",
    "\n",
    "    def pickUp():\n",
    "        return expr(f\"PickUp()\")\n",
    "\n",
    "    def putDown():\n",
    "        return expr(f\"PutDown()\")\n",
    "\n",
    "    # Observations, positive actions, negative actions\n",
    "\n",
    "    training_data = []\n",
    "    # Time 0: there's people at locations (0, 0) and (0, 3),\n",
    "    # the robot is at (0, 1) with empty hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f0\"),\n",
    "        personAt(\"L0f3\"),\n",
    "        robotNotAtPerson(),\n",
    "        robotNotAtHospital(),\n",
    "        robotAt(\"L0f1\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L0f0\") }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        # Importantly, do not include goTo(\"L0f3\")\n",
    "        # as a negative example, because it would work\n",
    "        # just as well as the positive example\n",
    "        pickUp(),\n",
    "        putDown(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "    \n",
    "    # Time 1: there's people at locations (0, 0) and (0, 3),\n",
    "    # the robot is at (0, 0) with empty hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f0\"),\n",
    "        personAt(\"L0f3\"),\n",
    "        robotAt(\"L0f0\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        robotNotAtHospital(),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { pickUp() }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        putDown(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 2: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 0) with full hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f3\"),\n",
    "        robotAt(\"L0f0\"),\n",
    "        robotNotAtPerson(),\n",
    "        robotNotAtHospital(),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L0f2\") }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        pickUp(),\n",
    "        putDown(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 3: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 2) with full hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f3\"),\n",
    "        robotNotAtPerson(),\n",
    "        robotAt(\"L0f2\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { putDown() }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        pickUp(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 4: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 2) with empty hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f3\"),\n",
    "        robotAt(\"L0f2\"),\n",
    "        robotNotAtPerson(),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L0f3\") }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        pickUp(),\n",
    "        putDown(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 5: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 3) with empty hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        personAt(\"L0f3\"),\n",
    "        robotAt(\"L0f3\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        robotNotAtHospital(),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { pickUp() }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        putDown(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 6: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 3) with full hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        robotAt(\"L0f3\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        robotNotAtHospital(),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L0f2\") }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        putDown(),\n",
    "        pickUp(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # Time 7: there's a person at location (0, 3),\n",
    "    # the robot is at (0, 2) with full hands\n",
    "    # and the hospital is at (0, 2).\n",
    "    obs = {\n",
    "        robotAt(\"L0f2\"),\n",
    "        hospitalAt(\"L0f2\"),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { putDown() }\n",
    "    bad_actions = {\n",
    "        goTo(\"L0f0\"),\n",
    "        goTo(\"L0f1\"),\n",
    "        goTo(\"L0f2\"),\n",
    "        goTo(\"L0f3\"),\n",
    "        pickUp(),\n",
    "    }\n",
    "    training_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    # These bad actions are not exhaustive, just a few to test\n",
    "    test_data = []\n",
    "    obs = {\n",
    "        personAt(\"L10f10\"),\n",
    "        personAt(\"L11f10\"),\n",
    "        personAt(\"L12f10\"),\n",
    "        hospitalAt(\"L5f5\"),\n",
    "        robotNotAtHospital(),\n",
    "        robotAt(\"L0f0\"),\n",
    "        robotNotAtPerson(),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L10f10\"), goTo(\"L11f10\"), goTo(\"L12f10\") }\n",
    "    bad_actions = { putDown(), pickUp() }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        personAt(\"L10f10\"),\n",
    "        personAt(\"L11f10\"),\n",
    "        personAt(\"L12f10\"),\n",
    "        hospitalAt(\"L5f5\"),\n",
    "        robotNotAtHospital(),\n",
    "        robotAt(\"L10f10\"),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { pickUp() }\n",
    "    bad_actions = { putDown(), goTo(\"L11f10\"), goTo(\"L5f5\") }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        personAt(\"L11f10\"),\n",
    "        personAt(\"L12f10\"),\n",
    "        hospitalAt(\"L5f5\"),\n",
    "        robotAt(\"L10f10\"),\n",
    "        robotNotAtHospital(),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L5f5\") }\n",
    "    bad_actions = { pickUp(), putDown(), goTo(\"L11f10\") }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        personAt(\"L11f10\"),\n",
    "        personAt(\"L12f10\"),\n",
    "        hospitalAt(\"L5f5\"),\n",
    "        robotNotAtPerson(),\n",
    "        robotAt(\"L5f5\"),\n",
    "        handFull(),\n",
    "    }\n",
    "    good_actions = { putDown() }\n",
    "    bad_actions = { pickUp(), goTo(\"L11f10\") }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    obs = {\n",
    "        personAt(\"L11f10\"),\n",
    "        personAt(\"L12f10\"),\n",
    "        hospitalAt(\"L5f5\"),\n",
    "        robotNotAtPerson(),\n",
    "        robotAt(\"L5f5\"),\n",
    "        handEmpty(),\n",
    "    }\n",
    "    good_actions = { goTo(\"L11f10\"), goTo(\"L12f10\") }\n",
    "    bad_actions = { pickUp(), putDown() }\n",
    "    test_data.append((obs, good_actions, bad_actions))\n",
    "\n",
    "    _test_ilp_helper(training_data, test_data)\n",
    "    \n",
    "def my_new_test():\n",
    "    \"\"\"Add a new test here!\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement me!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_traffic_light()\n",
    "test_search_and_rescue_policy_learning()\n",
    "my_new_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
