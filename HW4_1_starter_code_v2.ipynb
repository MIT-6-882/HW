{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.1 Starter Code v2\n",
    "\n",
    "See pset for deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.spaces.discrete import Discrete as DiscreteSpace\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import defaultdict, namedtuple\n",
    "_ = np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlickeringSAREnv(gym.Env):\n",
    "    \"\"\"A grid world with a number of different cell types that affect\n",
    "    only the local dynamics of the agent. With some darkness_prob, the\n",
    "    observations are null, otherwise, the state is fully observed. The\n",
    "    state is just the position of the agent. Actions are just up/down/\n",
    "    left/right.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    darkness_prob : float\n",
    "    \"\"\"\n",
    "    # Actions\n",
    "    ACTIONS = UP, DOWN, LEFT, RIGHT = range(4)\n",
    "    DELTAS = [(-1, 0), (1, 0), (0, -1), (0, 1), (0, 0)]\n",
    "\n",
    "    # Grid\n",
    "    CELL_TYPES = EMPTY, ICE, STICKY, TRAP, CONVEYOR = \\\n",
    "                 E, I, S, T, C = range(5)\n",
    "    # May generalize in the future, but for now, just one grid\n",
    "    GRID = np.array([\n",
    "        [T, T, T, T, T, T, T],\n",
    "        [T, E, E, C, E, E, T],\n",
    "        [T, E, S, E, I, E, T],\n",
    "        [T, E, E, I, I, S, T],\n",
    "        [T, E, E, E, I, S, T],\n",
    "        [T, C, E, C, C, E, T],\n",
    "        [T, T, T, T, T, T, T],\n",
    "    ], dtype=int)\n",
    "\n",
    "    def __init__(self, darkness_prob=0.):\n",
    "        self.action_space = DiscreteSpace(len(self.ACTIONS))\n",
    "        self._darkness_prob = darkness_prob\n",
    "        self._state = None # set in reset\n",
    "        self._rng = None # set in seed\n",
    "        self._delta_dists = {cell_type : {action : \\\n",
    "            self.get_delta_distribution(cell_type, action) \\\n",
    "            for action in self.ACTIONS} \\\n",
    "            for cell_type in self.CELL_TYPES}\n",
    "        super().__init__()\n",
    "\n",
    "    def seed(self, seed):\n",
    "        self._rng = np.random.RandomState(seed)\n",
    "        self.action_space.seed(seed)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset the state (position of agent in grid)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        observation : (int, int) or None\n",
    "            None for darkness\n",
    "        \"\"\"\n",
    "        assert self._rng is not None, \"Must call seed before reset\"\n",
    "        r = self._rng.choice(self.GRID.shape[0])\n",
    "        c = self._rng.choice(self.GRID.shape[1])\n",
    "        self._state = (r, c)\n",
    "        return self._get_observation()\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Update the state given the action\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        observation : (int, int) or None\n",
    "            None for darkness\n",
    "        reward : float\n",
    "            Always 0, including just for convention\n",
    "        done : bool\n",
    "            True if currently in trap\n",
    "        debug_info : dict\n",
    "            Including just for convention\n",
    "        \"\"\"\n",
    "        assert self._state is not None, \"Must call reset before step\"\n",
    "        # Get the current cell type\n",
    "        cell_type = self.GRID[self._state[0], self._state[1]]\n",
    "        # Get the local transition table\n",
    "        delta_dist = self._delta_dists[cell_type][action]\n",
    "        # Sample a delta\n",
    "        dr, dc = sample_from_dict(delta_dist, self._rng)\n",
    "        # Update state\n",
    "        r, c = self._state\n",
    "        assert 0 <= r + dr < self.GRID.shape[0] and \\\n",
    "               0 <= c + dc < self.GRID.shape[1]\n",
    "        self._state = (r + dr, c + dc)\n",
    "        # If we were in a trap, now we're done\n",
    "        done = (cell_type == self.TRAP)\n",
    "        obs = self._get_observation()\n",
    "        return obs, 0., done, {}\n",
    "\n",
    "    def _get_observation(self):\n",
    "        \"\"\"Handle darkness\n",
    "        \"\"\"\n",
    "        # Flip a coin for darkness\n",
    "        if self._rng.uniform() < self._darkness_prob:\n",
    "            return None\n",
    "        return tuple(self._state)\n",
    "\n",
    "    @classmethod\n",
    "    def get_delta_distribution(cls, cell_type, action):\n",
    "        \"\"\"This is what we'll try to recover through learning\n",
    "        \"\"\"\n",
    "        expected_delta = cls.DELTAS[action]\n",
    "\n",
    "        if cell_type == cls.EMPTY:\n",
    "            return { expected_delta : 1.0 }\n",
    "\n",
    "        if cell_type == cls.ICE:\n",
    "            return { delta : 1./len(cls.DELTAS) \\\n",
    "                     for delta in cls.DELTAS }\n",
    "\n",
    "        if cell_type == cls.STICKY:\n",
    "            return { expected_delta : 0.1, (0, 0) : 0.9 }\n",
    "\n",
    "        if cell_type == cls.TRAP:\n",
    "            return { (0, 0) : 1.0 }\n",
    "\n",
    "        if cell_type == cls.CONVEYOR:\n",
    "            return { (-1, 0) : 1.0 }\n",
    "\n",
    "        raise Exception(f\"Unrecognized cell type {cell_type}\")\n",
    "        \n",
    "\n",
    "def sample_from_dict(dict_probs, rng):\n",
    "    \"\"\"Helper utiliity\n",
    "    \"\"\"\n",
    "    assert abs(sum(dict_probs.values()) - 1.) < 1e-6, \\\n",
    "        \"Probabilities do not sum to 1.\"\n",
    "    choices, probs = zip(*dict_probs.items())\n",
    "    choice_idx = rng.choice(len(choices), p=probs)\n",
    "    return choices[choice_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belief Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RV = namedtuple(\"RV\", [\"name\", \"dim\"]) # Random Variable\n",
    "\n",
    "class Potential(namedtuple(\"Potential\", [\"rvs\", \"table\", \"hash_val\"])):\n",
    "    \"\"\"The same as the Potential from last pset, but with more efficient hashing\n",
    "    \"\"\"\n",
    "    __slots__ = ()\n",
    "\n",
    "    def __new__(cls, rvs, table):\n",
    "        hash_val = hash(tuple(rvs)) ^ hash(table.tobytes())\n",
    "        return super(Potential, cls).__new__(cls, rvs, table, hash_val)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return self.hash_val\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return hash(self) == hash(other)\n",
    "\n",
    "\n",
    "def run_belief_prop(rvs, potentials, max_iters=100):\n",
    "    \"\"\"Run belief propagation given random variables and potentials.\n",
    "    Return the final messages.\n",
    "    \"\"\"\n",
    "    # Initialize messages\n",
    "    msgs = defaultdict(dict)\n",
    "    for pot in potentials:\n",
    "        for rv in pot.rvs:\n",
    "            msgs[rv][pot] = np.ones(rv.dim) / rv.dim\n",
    "            msgs[pot][rv] = np.ones(rv.dim) / rv.dim\n",
    "\n",
    "    # Main loop\n",
    "    for it in range(max_iters):\n",
    "        new_msgs = {}\n",
    "\n",
    "        # Update variables\n",
    "        for rv in rvs:\n",
    "            # Compute belief\n",
    "            belief = np.prod([msgs[pot][rv] for pot in msgs[rv]], axis=0)\n",
    "            # Update outgoing messages\n",
    "            new_msgs[rv] = {pot : safe_divide(belief, msgs[pot][rv]) \\\n",
    "                            for pot in msgs[rv]}\n",
    "\n",
    "        # Update factors\n",
    "        for pot in potentials:\n",
    "            # Compute belief\n",
    "            belief = pot.table.copy()\n",
    "            all_idxs = list(range(len(pot.rvs)))\n",
    "            for rv in msgs[pot]:\n",
    "                msg = msgs[rv][pot]\n",
    "                idx = pot.rvs.index(rv)\n",
    "                belief = np.einsum(belief, all_idxs, msg, [idx], all_idxs)\n",
    "            # Update outgoing messages\n",
    "            new_msgs[pot] = {}\n",
    "            for rv in msgs[pot]:\n",
    "                msg = msgs[rv][pot]\n",
    "                idx = pot.rvs.index(rv)\n",
    "                msg_inv = safe_divide(1., msg)\n",
    "                msg_rv = np.einsum(belief, all_idxs, msg_inv, [idx], [idx])\n",
    "                new_msgs[pot][rv] = msg_rv\n",
    "\n",
    "        # Renormalize messages for numerical stability\n",
    "        converged = True\n",
    "        for src in new_msgs:\n",
    "            for snk in new_msgs[src]:\n",
    "                old_msg = msgs[src][snk]\n",
    "                new_msg = safe_divide(new_msgs[src][snk],\n",
    "                                      new_msgs[src][snk].sum())\n",
    "                new_msgs[src][snk] = new_msg\n",
    "                if converged and (np.any(np.abs(new_msg - old_msg) > 1e-6)):\n",
    "                    converged = False\n",
    "\n",
    "        if converged:\n",
    "            break\n",
    "\n",
    "        # Update messages\n",
    "        msgs = new_msgs\n",
    "\n",
    "    else:\n",
    "        print(\"WARNING: BP did not converge\")\n",
    "\n",
    "    return msgs\n",
    "\n",
    "def safe_divide(x, y):\n",
    "    \"\"\"Do x / y where at least one of x or y is a numpy array,\n",
    "    but convert any resulting infinities or NaNs to 0, so that\n",
    "    anything divided by 0 is 0.\n",
    "    \"\"\"\n",
    "    z = x / y\n",
    "    z[np.isinf(z) | np.isnan(z)] = 0.\n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(data, dark_prob, max_num_iters=10):\n",
    "    \"\"\"Expectation-maximization\n",
    "\n",
    "    The model that we're trying to learn is parameterized\n",
    "    by the delta distributions delta_dist[cell_type][action]\n",
    "    \"\"\"\n",
    "    # Keep track of all models for plotting\n",
    "    em_step_to_model = {}\n",
    "\n",
    "    # Initialize uniformly\n",
    "    deltas = FlickeringSAREnv.DELTAS\n",
    "    delta_dist = {cell_type : {action : {delta : 1./len(deltas) \\\n",
    "                  for delta in deltas} \\\n",
    "                  for action in FlickeringSAREnv.ACTIONS} \\\n",
    "                  for cell_type in FlickeringSAREnv.CELL_TYPES}\n",
    "\n",
    "    for it in range(max_num_iters):\n",
    "        print(f\"## Starting EM iteration {it}\")\n",
    "        em_step_to_model[it] = delta_dist\n",
    "\n",
    "        # E Step: compute marginals.\n",
    "        marginal_seq, action_seq = [], []\n",
    "\n",
    "        for episode, (observations, actions) in enumerate(data):\n",
    "            print(f\"Running E step on episode {episode}/{len(data)}\", end='\\r')\n",
    "            # Compute pairwise marginals over consecutive states.\n",
    "            # This is a list of dicts (cell_type, delta) -> prob.\n",
    "            marginals = compute_marginals(observations, actions, delta_dist,\n",
    "                                          dark_prob)\n",
    "            marginal_seq.extend(marginals)\n",
    "            action_seq.extend(actions)\n",
    "\n",
    "        # M Step: get MLE parameters\n",
    "        new_delta_dist = compute_mle_delta_dist(marginal_seq, action_seq)\n",
    "\n",
    "        # Check for convergence\n",
    "        max_dist = 0.\n",
    "        for cell_type in FlickeringSAREnv.CELL_TYPES:\n",
    "            for action in FlickeringSAREnv.ACTIONS:\n",
    "                old_dist = delta_dist[cell_type][action]\n",
    "                new_dist = new_delta_dist[cell_type][action]\n",
    "                if set(old_dist.keys()) != set(new_dist.keys()):\n",
    "                    converged = False\n",
    "                    break\n",
    "                for k in old_dist:\n",
    "                    max_dist = max(max_dist, abs(old_dist[k] - new_dist[k]))\n",
    "        converged = max_dist < 1e-4\n",
    "        print(\"\\nChange in model between iterations:\", max_dist)\n",
    "        if converged:\n",
    "            print(f\"EM converged after {it} iterations.\")\n",
    "            for i in range(it+1, max_num_iters+1):\n",
    "                em_step_to_model[i] = delta_dist\n",
    "            break\n",
    "\n",
    "        # Update dist\n",
    "        delta_dist = new_delta_dist\n",
    "\n",
    "    else:\n",
    "        print(\"WARNING: EM did not converge.\")\n",
    "        em_step_to_model[it+1] = delta_dist\n",
    "\n",
    "    return em_step_to_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_marginals(observations, actions, delta_dist, dark_prob):\n",
    "    \"\"\"Helper for the E step of EM. Given a list of observations\n",
    "    and corresponding actions, and the current model parameters\n",
    "    delta_dist, and the known observation model parameter dark_prob,\n",
    "    run inference to determine the marginal distributions over\n",
    "    (cell_type, delta), one per time step.\n",
    "\n",
    "    Create a factor graph with the following variables:\n",
    "        - One observation variable for each observation\n",
    "        - One state variable for each observation\n",
    "        - One action variable for each action\n",
    "    and the following potentials:\n",
    "        - One observation potential per observation,\n",
    "          relating the state and observation.\n",
    "          (Use dark_prob!)\n",
    "        - One transition potential per action,\n",
    "          relating the state, action, and next state.\n",
    "          (Use delta_dist!)\n",
    "\n",
    "    Notes:\n",
    "        - FlickeringSAREnv.ACTIONS are the actions\n",
    "        - FlickeringSAREnv.DELTAS are all possible local moves\n",
    "        - FlickeringSAREnv.GRID holds the cell type of each state\n",
    "\n",
    "    Run belief propagation on that factor graph. Use the\n",
    "    resulting messages to compute the joint distribution\n",
    "    over pairs of (state, next state).\n",
    "\n",
    "    Finally, use that joint pairwise distribution over states\n",
    "    to determine a distribution over (cell_type, delta) for\n",
    "    each time step. Note that the cell type is determined from\n",
    "    the state: FlickeringSAREnv.GRID[state[0], state[1]] is the\n",
    "    cell type; and delta is determined by the pair of states:\n",
    "    delta = (next_state[0] - state[0], next_state[1] - state[1]).\n",
    "\n",
    "    Return a list of dicts {(cell_type, delta) : prob}, one per\n",
    "    time step.\n",
    "    \"\"\"\n",
    "    T = len(observations)\n",
    "\n",
    "    # Set up variable spaces\n",
    "    action_domain = sorted(FlickeringSAREnv.ACTIONS)\n",
    "    state_domain = [(r, c) for r in range(FlickeringSAREnv.GRID.shape[0]) \\\n",
    "                           for c in range(FlickeringSAREnv.GRID.shape[1])]\n",
    "    obs_domain = state_domain + [None]\n",
    "\n",
    "    # Random variables\n",
    "    all_rvs = []\n",
    "    state_vars = {}\n",
    "    action_vars = {}\n",
    "    obs_vars = {}\n",
    "    for t in range(T):\n",
    "        state_t = RV(f\"state_{t}\", len(state_domain))\n",
    "        state_vars[t] = state_t\n",
    "        all_rvs.append(state_t)\n",
    "        obs_t = RV(f\"obs_{t}\", len(obs_domain))\n",
    "        obs_vars[t] = obs_t\n",
    "        all_rvs.append(obs_t)\n",
    "        if t < T-1:\n",
    "            action_t = RV(f\"action_{t}\", len(action_domain))\n",
    "            action_vars[t] = action_t\n",
    "            all_rvs.append(action_t)\n",
    "\n",
    "    # Potentials\n",
    "    pots = []\n",
    "    obs_potentials = {}\n",
    "    transition_potentials = {}\n",
    "    for t in range(T):\n",
    "        # Observation potential\n",
    "        rvs = [obs_vars[t], state_vars[t]]\n",
    "        table = np.zeros((obs_vars[t].dim, state_vars[t].dim))\n",
    "        # With 1.-dark prob, observe the state\n",
    "        assert obs_domain[-1] == None\n",
    "        table[:-1] = (1. - dark_prob)*np.eye(state_vars[t].dim)\n",
    "        # With dark prob, observe None\n",
    "        table[-1] = dark_prob\n",
    "        # Incorporate evidence\n",
    "        table = incorporate_potential_evidence(rvs, table,\n",
    "            obs_vars[t], obs_domain.index(observations[t]))\n",
    "        observation_potential_t = Potential(rvs, table)\n",
    "        obs_potentials[t] = observation_potential_t\n",
    "        pots.append(observation_potential_t)\n",
    "        if t < T - 1:\n",
    "            # Transition potential\n",
    "            rvs = [state_vars[t], action_vars[t], state_vars[t+1]]\n",
    "            # Build up transitions\n",
    "            table = np.zeros((state_vars[t].dim, action_vars[t].dim,\n",
    "                              state_vars[t+1].dim))\n",
    "            for i, (r, c) in enumerate(state_domain):\n",
    "                cell_type = FlickeringSAREnv.GRID[r, c]\n",
    "                for j, a in enumerate(action_domain):\n",
    "                    for (dr, dc), p in delta_dist[cell_type][a].items():\n",
    "                        # Can't go off screen\n",
    "                        if not (0 <= r + dr < FlickeringSAREnv.GRID.shape[0]) or \\\n",
    "                           not (0 <= c + dc < FlickeringSAREnv.GRID.shape[1]):\n",
    "                           continue\n",
    "                        k = state_domain.index((r+dr, c+dc))\n",
    "                        table[i, j, k] += p\n",
    "            # Incorporate evidence\n",
    "            table = incorporate_potential_evidence(rvs, table,\n",
    "                action_vars[t], action_domain.index(actions[t]))\n",
    "            transition_potential_t = Potential(rvs, table)\n",
    "            transition_potentials[t] = transition_potential_t\n",
    "            pots.append(transition_potential_t)\n",
    "\n",
    "    # Run BP\n",
    "    msgs = run_belief_prop(all_rvs, pots)\n",
    "\n",
    "    # Get marginal distribution over consecutive states\n",
    "    marginal_state_pairs = []\n",
    "    for t in range(T-1):\n",
    "        # Start with joint factor\n",
    "        joint = transition_potentials[t].table[:, actions[t]]\n",
    "        # Get forward message\n",
    "        if t > 0:\n",
    "            forward_msg = msgs[transition_potentials[t-1]][state_vars[t]]\n",
    "            joint *= forward_msg[:, np.newaxis]\n",
    "        # Get backward message\n",
    "        if t < T-2:\n",
    "            backward_msg = msgs[transition_potentials[t+1]][state_vars[t+1]]\n",
    "            joint *= backward_msg[np.newaxis, :]\n",
    "        # Get observations\n",
    "        obs_t_msg = msgs[obs_potentials[t]][state_vars[t]]\n",
    "        joint *= obs_t_msg[:, np.newaxis]\n",
    "        obs_t1_msg = msgs[obs_potentials[t+1]][state_vars[t+1]]\n",
    "        joint *= obs_t1_msg[np.newaxis, :]\n",
    "        # Normalize\n",
    "        joint = safe_divide(joint, joint.sum())\n",
    "        marginal_state_pairs.append(joint)\n",
    "\n",
    "    # Convert into marginal distribution over (cell type, delta)\n",
    "    beliefs = []\n",
    "    for t in range(T-1):\n",
    "        joint = marginal_state_pairs[t]\n",
    "        belief_t = defaultdict(float)\n",
    "        for i, s_t in enumerate(state_domain):\n",
    "            cell_type = FlickeringSAREnv.GRID[s_t[0], s_t[1]]\n",
    "            for j, s_t1 in enumerate(state_domain):\n",
    "                delta = (s_t1[0] - s_t[0], s_t1[1] - s_t[1])\n",
    "                # If not in deltas, not possible\n",
    "                if delta not in FlickeringSAREnv.DELTAS:\n",
    "                    continue\n",
    "                belief_t[(cell_type, delta)] += joint[i, j]\n",
    "        # Renormalize due to deltas\n",
    "        z = sum(belief_t.values())\n",
    "        belief_t = {k : v/z for k, v in belief_t.items()}\n",
    "        beliefs.append(belief_t)\n",
    "\n",
    "    return beliefs\n",
    "\n",
    "def incorporate_potential_evidence(rvs, table, rv, val):\n",
    "    \"\"\"Zero out any potential values that are inconsistent with evidence\n",
    "    \n",
    "    Helper for E step. Use me!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rvs : [ RV ]\n",
    "        List of random variables, axes of the table.\n",
    "    table : np.ndarray\n",
    "        The potential values\n",
    "    rv : RV\n",
    "        The random variable for which we have evidence\n",
    "    val : int\n",
    "        The value for the evidence rv.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    table : np.ndarray\n",
    "        With inconsistent entries zeroed out.\n",
    "    \"\"\"\n",
    "    if rv not in rvs:\n",
    "        return table\n",
    "    all_idxs = list(range(len(rvs)))\n",
    "    all_vals = list(range(rv.dim))\n",
    "    idx = rvs.index(rv)\n",
    "    zero_idxs = [all_vals[:val] + all_vals[val+1:] \\\n",
    "                 if i == idx else slice(None) \\\n",
    "                 for i in all_idxs]\n",
    "    table[tuple(zero_idxs)] = 0.\n",
    "    assert table.sum() > 0.\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mle_delta_dist(marginal_seq, action_seq, laplace=0.01):\n",
    "    \"\"\"Helper for the M step of EM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    marginal_seq : [{(int, (int, int)) : float}]\n",
    "        A sequence of marginals, where each marginal is a joint\n",
    "        distribution of (cell_type, delta), represented as a dict\n",
    "        so that marginal_seq[t][(cell_type, delta)] is the marginal\n",
    "        probability that the state at time t had cell type cell_type\n",
    "        and that the delta between times t and t+1 was delta.\n",
    "    action_seq : [int]\n",
    "        Sequence of actions of the same length as marginal_seq.\n",
    "    laplace : float\n",
    "        Additive smoothing parameter.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delta_dist : {int : {int : {(int, int) : float}}}\n",
    "        The learned distribution.\n",
    "        delta_dist[cell_type][action][delta] is the probability\n",
    "        of moving delta after being in cell_type and taking action.\n",
    "\n",
    "    Notes:\n",
    "        - FlickeringSAREnv.ACTIONS are the actions\n",
    "        - FlickeringSAREnv.DELTAS are all possible local moves\n",
    "        - FlickeringSAREnv.GRID holds the cell type of each state\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Implement me!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(darkness_prob, num_transitions,\n",
    "                   max_transitions_per_episode, seed=0):\n",
    "    \"\"\"Gather a dataset of transitions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transitions : [([observations], [actions])]\n",
    "        Observation are hashable, actions are integers.\n",
    "    \"\"\"\n",
    "    transitions = []\n",
    "    env = FlickeringSAREnv(darkness_prob=darkness_prob)\n",
    "    env.seed(seed)\n",
    "    done = True\n",
    "    for _ in range(num_transitions):\n",
    "        if done:\n",
    "            episode_t = 0\n",
    "            obs = env.reset()\n",
    "            transitions.append([[obs], []])\n",
    "        action = env.action_space.sample()\n",
    "        transitions[-1][1].append(action)\n",
    "        obs, _, done, _ = env.step(action)\n",
    "        transitions[-1][0].append(obs)\n",
    "        episode_t += 1\n",
    "        if episode_t >= max_transitions_per_episode:\n",
    "            done= True\n",
    "    return transitions\n",
    "\n",
    "def evaluate_model(model, verbose=False):\n",
    "    \"\"\"Compute the average total variational distance to ground truth\n",
    "    \"\"\"\n",
    "    tvds = []\n",
    "    for cell_type in FlickeringSAREnv.CELL_TYPES:\n",
    "        for action in FlickeringSAREnv.ACTIONS:\n",
    "            ground_truth = FlickeringSAREnv.get_delta_distribution(\n",
    "                cell_type, action)\n",
    "            tvd = 0.\n",
    "            for delta in FlickeringSAREnv.DELTAS:\n",
    "                gt = ground_truth.get(delta, 0.)\n",
    "                md = model[cell_type][action].get(delta, 0.)\n",
    "                if verbose:\n",
    "                    print(f\"{cell_type}, {action}, {delta}: {md} [{gt}]\")\n",
    "                tvd = max(tvd, abs(gt - md))\n",
    "            tvds.append(tvd)\n",
    "    return np.mean(tvds)\n",
    "\n",
    "def main():\n",
    "    \"\"\"Gather data, learn a model, evaluate the model.\n",
    "    \n",
    "    This will take 5-10 minutes to run from start to finish, so you will\n",
    "    probably want to mess with the hyperparameters to make it faster as you\n",
    "    are developinig your code.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    darkness_probs = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "    max_em_iters = 10\n",
    "    iters_to_plot = [0, 1, 2, 3, 5, 10]\n",
    "    num_trials_per_darkness_prob = 5\n",
    "    num_transitions_per_trial = 300\n",
    "    max_transitions_per_episode = 10\n",
    "\n",
    "    results = {}\n",
    "    for darkness_prob in darkness_probs:\n",
    "        results[darkness_prob] = {i : [] for i in range(max_em_iters+1)}\n",
    "        for seed in range(num_trials_per_darkness_prob):\n",
    "            # Gather demonstration data (random actions)\n",
    "            data = create_dataset(darkness_prob, num_transitions_per_trial,\n",
    "                                  max_transitions_per_episode, seed=seed)\n",
    "            # Learn a model\n",
    "            em_step_to_model = learn_model(data, darkness_prob,\n",
    "                max_num_iters=max_em_iters)\n",
    "            for em_step, model in em_step_to_model.items():\n",
    "                # Evaluate the model\n",
    "                tvd = evaluate_model(model)\n",
    "                # Record result\n",
    "                results[darkness_prob][em_step].append(tvd)\n",
    "\n",
    "    # Plot darkness prob versus total variational distance\n",
    "    x = np.array(darkness_probs)\n",
    "    plt.figure()\n",
    "    plt.title(\"Learning Sequential Hidden State Models for S&R\")\n",
    "    plt.xlabel(\"Darkness Probability\")\n",
    "    plt.ylabel(\"Total Variational Distance from Ground Truth\")\n",
    "    for it in iters_to_plot:\n",
    "        y_mean = np.mean([results[p][it] for p in x], axis=1)\n",
    "        y_std = np.std([results[p][it] for p in x], axis=1)\n",
    "        p = plt.plot(x, y_mean, marker='s', label=f'{it} EM iters')\n",
    "        color = p[0].get_color()\n",
    "        plt.fill_between(x, y_mean+y_std, y_mean-y_std, facecolor=color,\n",
    "                         alpha=0.25)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Finished run in {time.time() - start_time} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fire Away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
